{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Profiling the Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part we try to extract features that represents the content of a certain track. We tried two kind of features: lyrics features and audio features. Finally, the lyrics of a song is reduced to a 4-entry profile and the audio features of a song is reduced to a 9-entry profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lyrics - Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1). Baseline Model for Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to generate a playlist whose songs have similar emotions to the tracks in the seeding playlist. In order to do this, we need to automatically recognize the emotion of a certain track. We chose lyrics as our predictor. The main reason for this choice is that raw data on lyrics are easier to obtain compared to raw acoustic data since recordings of most of the tracks are subject to copyright. After comparing several combinations of input representation and model, we chose feature hashing as the input representation and random forest as the model. This pipeline should act as a baseline model for our future improvement.\n",
    "\n",
    "The target values used in model training come from last.fm dataset. We used tracks tagged with 'happy' and 'sad' for model selection. These two emotions are less subtle (compared to, say, ‘bittersweet’) and we can assume these two emotions are mutually exclusive. These properties simplify both the classification task and our evaluation of the classification results. We then try to match the tag with lyrics in musiXmatch dataset and LyricWiki.\n",
    "There are two sources of input for our model. They are preprocessed in different ways. The first source of input is lyrics as BOW from the musiXmatch dataset. The second is raw lyrics from LyricWiki. For lyrics as BOW, we applied the term-frequency-inverse-document-frequency transformation (TF-IDF) to lower the weights of common words in the lyrics, which have lower prediction power. We tried using PCA to reduce the dimensionality, but the resulting improvement in training is limited and does not make up for the drop in model performance. Therefore, no dimensionality reduction is applied. For raw lyrics, we extracted features by feature hashing (as implemented by sklearn’s HashingVectorizer). For both sources of input, we removed the songs that are tagged but has not lyrics (instrumental). \n",
    "In the end, we have ~10,000 instances from the first source, and ~5,000 instances from the second source. The number of instances from the second source is significantly lower because we haven’t finished scraping LyricsWiki and our data for raw lyrics is incomplete (And there might be songs that are included in the musiXmatch dataset but not LyricWiki).\n",
    "\n",
    "We used the following models for classification: support vector machine (SVM), random forest, Gaussian naive Bayes and logistic regression. We used 50% of our instances as the training set and the other half as the validation set. We tried each combination of input representation and model. The model is trained on the training set and evaluated by the validation set. Our pipeline can be summarized as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import json\n",
    "from scipy.sparse                    import csr_matrix, vstack\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, HashingVectorizer\n",
    "from sklearn.svm                     import SVC\n",
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.naive_bayes             import GaussianNB\n",
    "from sklearn.linear_model            import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MXM_PATH  = 'databases/mxm_dataset.db'\n",
    "TAG_PATH  = 'databases/lastfm_tags.db'\n",
    "META_PATH = 'databases/track_metadata.db'\n",
    "WIKI_PATH = 'databases/lyricwiki.db'\n",
    "\n",
    "conn_mxm  = sqlite3.connect(MXM_PATH)\n",
    "conn_tag  = sqlite3.connect(TAG_PATH)\n",
    "conn_meta = sqlite3.connect(META_PATH)\n",
    "conn_wiki = sqlite3.connect(WIKI_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOW + TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the list of 5000 words used for musiXmatch's BOW representation\"\"\"\n",
    "def get_mxm_vocab(conn_mxm):\n",
    "    sql  = \"SELECT * FROM words\"\n",
    "    res  = conn_mxm.execute(sql)\n",
    "    data = res.fetchall()\n",
    "    mxm_vocab = [t[0] for t in data]\n",
    "    return mxm_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_vocab = get_mxm_vocab(conn_mxm)\n",
    "mxm_dict  = {mxm_vocab[i] : i for i in range(len(mxm_vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the BOW regresentation of the tracks in the form of a sparse matrix\"\"\"\n",
    "def get_bagofwords(tids, mxm_dict, conn_mxm):\n",
    "    bows = []\n",
    "    for tid in tids:\n",
    "        sql  = \"SELECT word, count FROM lyrics WHERE track_id='{}'\".format(tid)\n",
    "        res  = conn_mxm.execute(sql)\n",
    "        data = res.fetchall()\n",
    "        col  = np.array([mxm_dict[t[0]] for t in data], dtype=np.int16)\n",
    "        row  = np.zeros(len(col),                       dtype=np.int16)\n",
    "        cnt  = np.array([t[1] for t in data] )\n",
    "        bow  = csr_matrix((cnt, (row, col)), shape=(1, 5000))\n",
    "        bows.append(bow)\n",
    "    return vstack(bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the track ids. tagged with a certain tag\"\"\"\n",
    "def get_tids_oftag(tag, conn_tag):\n",
    "    sql  = \"\"\"SELECT tids.tid FROM tid_tag, tids, tags \n",
    "              WHERE tids.ROWID=tid_tag.tid AND tid_tag.tag=tags.ROWID \n",
    "              AND tags.tag='{}'\"\"\".format(tag)\n",
    "    res  = conn_tag.execute(sql)\n",
    "    data = res.fetchall()\n",
    "    return [t[0] for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the BOW representation for tracks labelled with 'happy' and 'sad'.\n",
    "happy_tids = get_tids_oftag('happy', conn_tag)\n",
    "happy_bows = get_bagofwords(happy_tids, mxm_dict, conn_mxm)\n",
    "sad_tids   = get_tids_oftag('sad',   conn_tag)\n",
    "sad_bows   = get_bagofwords(sad_tids, mxm_dict,   conn_mxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24716, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the term frequency - inverse document frequency transformation.\n",
    "all_bows = vstack([happy_bows, sad_bows])\n",
    "tfidf = TfidfTransformer()\n",
    "all_bows_tfidf = tfidf.fit_transform(all_bows)\n",
    "all_bows_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_bows_tfidf.copy().toarray()\n",
    "y = ['happy']*(happy_bows.shape[0]) + \\\n",
    "    ['sad']*(sad_bows.shape[0])\n",
    "y = np.array([1 if t == 'happy' else 0 for t in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzeros = np.sum(X, axis=1) != 0.0\n",
    "X_nonzero = X[nonzeros]\n",
    "y_nonzero = y[nonzeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_nonzero, y_nonzero, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=70, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    n_estimators=300, max_features=70, max_depth=None, min_samples_split=2)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984089845577913"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6620399251403618"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive = GaussianNB()\n",
    "naive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7622835751052878"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5920149719276356"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenfeiyu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719544532834192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6781035558328135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n",
      "got\n",
      "danc\n",
      "gonna\n",
      "get\n",
      "happi\n",
      "rock\n",
      "up\n",
      "about\n",
      "citi\n",
      "fine\n",
      "shine\n",
      "doo\n",
      "jump\n",
      "fun\n",
      "kiss\n",
      "hot\n",
      "sky\n",
      "check\n",
      "ya\n"
     ]
    }
   ],
   "source": [
    "# Let's see the top 20 words that indicate happiness\n",
    "top = np.argsort(logreg.coef_[0])[::-1]\n",
    "for i in top[:20]: \n",
    "    print(mxm_vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenfeiyu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5484323818437061"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5483468496568933"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw lyrics + feature hashing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the artist and title for tracks with tids\"\"\"\n",
    "def get_artistsandtitles(tids, conn_meta):\n",
    "    AandTs = []\n",
    "    for tid in tids:\n",
    "        sql = \"SELECT artist_name, title FROM songs WHERE track_id='{}'\".format(tid)\n",
    "        res = conn_meta.execute(sql)\n",
    "        AandTs.append(res.fetchall()[0])\n",
    "    return AandTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Get the raw lyrics of songs with certain artist and title\"\"\"\n",
    "def get_lyrics(AandTs, conn_wiki):\n",
    "    queryconds = [(t[0].lower().strip(), t[1].lower().strip()) for t in AandTs]\n",
    "    lyricslist = []\n",
    "    total_found = 0\n",
    "    for n, t in enumerate(queryconds):\n",
    "        res = conn_wiki.execute(\"\"\"SELECT lyrics FROM songs WHERE artist=? AND title=?\"\"\", (t[0], t[1]))\n",
    "        try:\n",
    "            lyricslist.append(res.fetchall()[0][0])\n",
    "            total_found = total_found + 1\n",
    "        except:\n",
    "            continue\n",
    "    return lyricslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_AandTs = get_artistsandtitles(happy_tids, conn_meta)\n",
    "happy_lyrics = get_lyrics(happy_AandTs, conn_wiki)\n",
    "sad_AandTs   = get_artistsandtitles(sad_tids,   conn_meta)\n",
    "sad_lyrics   = get_lyrics(sad_AandTs,   conn_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonempty(lyrics):\n",
    "    nonempty = []\n",
    "    for l in lyrics:\n",
    "        if len(l) > 0:\n",
    "            nonempty.append(l)\n",
    "    return nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_lyrics_nonempty = get_nonempty(happy_lyrics)\n",
    "sad_lyrics_nonempty   = get_nonempty(sad_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(n_features=1000)\n",
    "anotherX   = vectorizer.fit_transform(\n",
    "    happy_lyrics_nonempty+sad_lyrics_nonempty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anothery = ['happy']*(len(happy_lyrics_nonempty)) \\\n",
    "    + ['sad']*(len(sad_lyrics_nonempty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotherX_train, anotherX_test, anothery_train, anothery_test = train_test_split(\n",
    "    anotherX, anothery, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=30, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherforest = RandomForestClassifier(\n",
    "    n_estimators=300, max_features=30, max_depth=None, min_samples_split=2)\n",
    "anotherforest.fit(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799670044779637"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherforest.score(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509131613055261"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherforest.score(anotherX_test, anothery_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothernaive = GaussianNB()\n",
    "anothernaive.fit(anotherX_train.toarray(), anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6586141880744756"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothernaive.score(anotherX_train.toarray(), anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615411806291976"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothernaive.score(anotherX_test.toarray(), anothery_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenfeiyu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherlogreg = LogisticRegression()\n",
    "anotherlogreg.fit(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7231911383455103"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherlogreg.score(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6849298927771886"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherlogreg.score(anotherX_test, anothery_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenfeiyu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothersvc = SVC()\n",
    "anothersvc.fit(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5136695734150365"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothersvc.score(anotherX_train, anothery_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5167903852951573"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anothersvc.score(anotherX_test, anothery_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the models is summarized as below\n",
    "\n",
    "|                 | SVM | Random Forest | Gaussian Naive Bayes | Logistic Regression |\n",
    "|-----------------|-----|---------------|----------------------|---------------------|\n",
    "| BOW + TF-IDF    | 55% | 66%           | 56%                  | 67%                 |\n",
    "| Feature hashing | 52% | 75%           | 62%                  | 68%                 |\n",
    "\n",
    "Based on the accuracy scores below, we chose feature hashing + random forest as our baseline model because it has the highest validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2). Comparing LSTM with Baseline Model for Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our baseline model the lyrics is essitially represented by the words that appear in it. However, the meaning of text not only depends on the presence of certain words, but also the order of their presence. Therefore we tried using Long Short Term Memory (LSTM) to capture this information. We included a word embedding layer to learn the word2vec representation of the words, and a CNN layer to capture the translational invariance in the lyrics. We compared the performance of this model to our baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training set and Validation set for comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected four set of emotions to compare the performance of our baseline model and the new model. The four set of emotions are happy-sad, relax-energetic, cool-oldies, sweet-dark. Again, we selected polarized emotion pairs in purpose, so that we can assume the tracks tagged with one emotion from a pair won't be tagged with another emotion in the same pair. These four pairs of emotions later formed our profile for each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langdetect              import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filter out non-English lyrics\"\"\"\n",
    "def get_english(lyrics):\n",
    "    english = []\n",
    "    for l in lyrics:\n",
    "        try:\n",
    "            if detect(l) == 'en':\n",
    "                english.append(l)\n",
    "        except: continue\n",
    "    return english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create training set and validation for bi-polar tags.\"\"\"\n",
    "def create_train_test(tag1, tag2):\n",
    "    print('Collecting tids...')\n",
    "    tag1_tids = get_tids_oftag(tag1, conn_tag)\n",
    "    tag2_tids = get_tids_oftag(tag2, conn_tag)\n",
    "    print('Collecting artists and titles...')\n",
    "    tag1_AandTs = get_artistsandtitles(tag1_tids, conn_meta)\n",
    "    tag2_AandTs = get_artistsandtitles(tag2_tids, conn_meta)\n",
    "    print('Collecting lyrics...')\n",
    "    tag1_lyrics = get_lyrics(tag1_AandTs, conn_wiki)\n",
    "    tag2_lyrics = get_lyrics(tag2_AandTs, conn_wiki)\n",
    "    print('{} tracks collected for tag {}, {} tracks collected for tag {}'.format(\\\n",
    "          len(tag1_lyrics), tag1, len(tag2_lyrics), tag2))\n",
    "    print('Filtering out empty lyrics...')\n",
    "    tag1_lyrics_nonempty = get_nonempty(tag1_lyrics)\n",
    "    tag2_lyrics_nonempty = get_nonempty(tag2_lyrics)\n",
    "    print('Filtering out non-English lyrics...')\n",
    "    tag1_lyrics_nonempty = get_english(tag1_lyrics_nonempty)\n",
    "    tag2_lyrics_nonempty = get_english(tag2_lyrics_nonempty)\n",
    "    print('{} nonempty lyrics for tag {}, {} nonempty lyrics for tag {}'.format(\\\n",
    "          len(tag1_lyrics_nonempty), tag1, len(tag2_lyrics_nonempty), tag2))\n",
    "    print('Creating predictor set and target set...')\n",
    "    X = np.array(        tag1_lyrics_nonempty  +         tag2_lyrics_nonempty )\n",
    "    y = np.array([1]*len(tag1_lyrics_nonempty) + [0]*len(tag2_lyrics_nonempty))\n",
    "    print('Splitting training set and validation set...')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    print('writing to disk...')\n",
    "    dirname = tag1+'-'+tag2\n",
    "    os.mkdir(dirname)\n",
    "    np.save(dirname + '/X_train.npy', X_train)\n",
    "    np.save(dirname + '/X_test.npy',  X_test)\n",
    "    np.save(dirname + '/y_train.npy', y_train)\n",
    "    np.save(dirname + '/y_test.npy',  y_test)\n",
    "    print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "8508 tracks collected for tag happy, 9078 tracks collected for tag sad\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "7724 nonempty lyrics for tag happy, 8300 nonempty lyrics for tag sad\n",
      "Creating predictor set and target set...\n",
      "Splitting training set and validation set...\n",
      "writing to disk...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_train_test('happy', 'sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "6287 tracks collected for tag relax, 4521 tracks collected for tag Energetic\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "5213 nonempty lyrics for tag relax, 4068 nonempty lyrics for tag Energetic\n",
      "Creating predictor set and target set...\n",
      "Splitting training set and validation set...\n",
      "writing to disk...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_train_test('relax', 'Energetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "12457 tracks collected for tag cool, 12769 tracks collected for tag oldies\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "11064 nonempty lyrics for tag cool, 11970 nonempty lyrics for tag oldies\n",
      "Creating predictor set and target set...\n",
      "Splitting training set and validation set...\n",
      "writing to disk...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_train_test('cool', 'oldies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "5169 tracks collected for tag sweet, 4768 tracks collected for tag dark\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "4773 nonempty lyrics for tag sweet, 4228 nonempty lyrics for tag dark\n",
      "Creating predictor set and target set...\n",
      "Splitting training set and validation set...\n",
      "writing to disk...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_train_test('sweet', 'dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance of baseline model (feature hashing + random forest) vs new model (word2vec + LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models                    import Sequential\n",
    "from keras.layers                    import Dense, Conv1D, MaxPooling1D, LSTM, Dropout\n",
    "from keras.layers.embeddings         import Embedding\n",
    "from keras.preprocessing             import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(tag1, tag2):\n",
    "    dirname = tag1 + '-' + tag2\n",
    "    vectorizer = HashingVectorizer(n_features=1000)\n",
    "    \n",
    "    print('Preprocessing training set...')\n",
    "    X_train_forest = vectorizer.fit_transform(np.load(dirname + '/X_train.npy'))\n",
    "    y_train_forest = np.load(dirname + '/y_train.npy')\n",
    "    print('Preprocessing validation set...')\n",
    "    X_test_forest  = vectorizer.transform(np.load(dirname + '/X_test.npy'))\n",
    "    y_test_forest  = np.load(dirname + '/y_test.npy')\n",
    "    print('Training random forest...')\n",
    "    forest = RandomForestClassifier(\n",
    "    n_estimators=300, max_features=30, max_depth=None, min_samples_split=2)\n",
    "    forest.fit(X_train_forest, y_train_forest)\n",
    "    print('Finished.')\n",
    "    return forest, vectorizer, X_train_forest, y_train_forest, X_test_forest, y_test_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(res):\n",
    "    print('Training accuracy:', res[0].score(res[2], res[3]))\n",
    "    print('Validation accuracy:', res[0].score(res[4], res[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics2intarray(lyrics, tokenizer, stemmer):\n",
    "    lyrics_tokenized = tokenizer.tokenize(lyrics)\n",
    "    lyrics_stemmed   = [stemmer.stem(w) for w in lyrics_tokenized]\n",
    "    L = len(lyrics_stemmed)\n",
    "    intarray = np.zeros(L, dtype=np.int32)\n",
    "    for i in range(L):\n",
    "        intarray[i] = mxm_dict.get(lyrics_stemmed[i], 0)\n",
    "    return intarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(tag1, tag2):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    dirname = tag1 + '-' + tag2\n",
    "    print('Preprocessing training set...')\n",
    "    X_train_lstm = [lyrics2intarray(l, tokenizer, stemmer) for l in np.load(dirname + '/X_train.npy')]\n",
    "    y_train_lstm = np.load(dirname + '/y_train.npy')\n",
    "    print('Preprocessing validation set...')\n",
    "    X_test_lstm  = [lyrics2intarray(l, tokenizer, stemmer) for l in np.load(dirname + '/X_test.npy')]\n",
    "    y_test_lstm  = np.load(dirname + '/y_test.npy')\n",
    "    print('Trimming input...')\n",
    "    max_lyrics_length = 150\n",
    "    X_train_lstm = sequence.pad_sequences(X_train_lstm, maxlen=max_lyrics_length)\n",
    "    X_test_lstm  = sequence.pad_sequences(X_test_lstm,  maxlen=max_lyrics_length)\n",
    "    print('Training LSTM...')\n",
    "    embedding_vecor_length = 64\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5001, embedding_vecor_length, input_length=max_lyrics_length))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(X_train_lstm, y_train_lstm, validation_data=(X_test_lstm, y_test_lstm), epochs=5, batch_size=64)\n",
    "    return model, X_train_lstm, y_train_lstm, X_test_lstm, y_test_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Training random forest...\n",
      "Finished.\n",
      "Training accuracy: 0.9726187690147438\n",
      "Validation accuracy: 0.7759750390015601\n"
     ]
    }
   ],
   "source": [
    "show_performance(train_forest('happy', 'sad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Trimming input...\n",
      "Training LSTM...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 64)           320064    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 150, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 355,467\n",
      "Trainable params: 355,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 12819 samples, validate on 3205 samples\n",
      "Epoch 1/5\n",
      "12819/12819 [==============================] - 21s 2ms/step - loss: 0.6661 - acc: 0.5842 - val_loss: 0.5918 - val_acc: 0.6871\n",
      "Epoch 2/5\n",
      "12819/12819 [==============================] - 20s 2ms/step - loss: 0.5624 - acc: 0.7176 - val_loss: 0.5645 - val_acc: 0.7236\n",
      "Epoch 3/5\n",
      "12819/12819 [==============================] - 20s 2ms/step - loss: 0.5041 - acc: 0.7664 - val_loss: 0.5555 - val_acc: 0.7310\n",
      "Epoch 4/5\n",
      "12819/12819 [==============================] - 21s 2ms/step - loss: 0.4722 - acc: 0.7859 - val_loss: 0.5509 - val_acc: 0.7282\n",
      "Epoch 5/5\n",
      "12819/12819 [==============================] - 20s 2ms/step - loss: 0.4455 - acc: 0.7992 - val_loss: 0.5492 - val_acc: 0.7351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x1103d89b0>,\n",
       " array([[   0,    0,    0, ...,   25,   14, 1112],\n",
       "        [ 141,    2, 1318, ...,   59,    2,  513],\n",
       "        [  92,    3,   16, ...,  107,   10, 2921],\n",
       "        ...,\n",
       "        [ 134,   35,  169, ...,    3,    4,   29],\n",
       "        [   0,    0,    0, ...,   13,   27,    7],\n",
       "        [1001,  245,  503, ...,  119,   13,  154]], dtype=int32),\n",
       " array([0, 0, 1, ..., 1, 1, 0]),\n",
       " array([[   0,    2,    0, ...,    7,   37,  941],\n",
       "        [ 880,    3,    3, ...,  545, 1748, 1543],\n",
       "        [  14,  542,   46, ...,   15,    3,   16],\n",
       "        ...,\n",
       "        [   0,    0,    0, ..., 1803,   11,  569],\n",
       "        [  12,    9,    2, ...,  416,  264,  200],\n",
       "        [  61,   36,   30, ...,  171, 1222,  125]], dtype=int32),\n",
       " array([0, 0, 0, ..., 1, 0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm('happy', 'sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Training random forest...\n",
      "Finished.\n",
      "Training accuracy: 0.9888200431034483\n",
      "Validation accuracy: 0.7926763597199784\n"
     ]
    }
   ],
   "source": [
    "show_performance(train_forest('relax', 'Energetic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Trimming input...\n",
      "Training LSTM...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 64)           320064    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 150, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 355,467\n",
      "Trainable params: 355,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7424 samples, validate on 1857 samples\n",
      "Epoch 1/5\n",
      "7424/7424 [==============================] - 13s 2ms/step - loss: 0.6794 - acc: 0.5672 - val_loss: 0.6409 - val_acc: 0.6462\n",
      "Epoch 2/5\n",
      "7424/7424 [==============================] - 12s 2ms/step - loss: 0.5830 - acc: 0.6989 - val_loss: 0.5570 - val_acc: 0.7264\n",
      "Epoch 3/5\n",
      "7424/7424 [==============================] - 12s 2ms/step - loss: 0.4871 - acc: 0.7736 - val_loss: 0.5433 - val_acc: 0.7329\n",
      "Epoch 4/5\n",
      "7424/7424 [==============================] - 12s 2ms/step - loss: 0.4351 - acc: 0.8110 - val_loss: 0.5338 - val_acc: 0.7485\n",
      "Epoch 5/5\n",
      "7424/7424 [==============================] - 12s 2ms/step - loss: 0.3794 - acc: 0.8450 - val_loss: 0.5442 - val_acc: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x1a319659e8>,\n",
       " array([[  83,    1,   61, ...,  135,    3,   37],\n",
       "        [  28, 3422,    2, ...,  976,  523,  172],\n",
       "        [   0,    0,    0, ...,  254,   59,  390],\n",
       "        ...,\n",
       "        [ 267,    4,  251, ...,  336,    6,   92],\n",
       "        [  53,  476,   28, ...,   65,  175,  175],\n",
       "        [1298,    2, 1950, ...,  312,   46,   46]], dtype=int32),\n",
       " array([0, 1, 0, ..., 1, 0, 0]),\n",
       " array([[   0,    0,    0, ...,  147,  131,    3],\n",
       "        [  48,  103,  476, ...,  885,    0,  106],\n",
       "        [ 687, 1109,   13, ...,   15,    3,   84],\n",
       "        ...,\n",
       "        [4717,  103,  476, ...,  539,   13, 1685],\n",
       "        [ 399,    1, 1362, ...,   30,   12,  399],\n",
       "        [   0,  135,    0, ...,    0,  336, 1672]], dtype=int32),\n",
       " array([1, 0, 1, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm('relax', 'Energetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Training random forest...\n",
      "Finished.\n",
      "Training accuracy: 0.9468171704563955\n",
      "Validation accuracy: 0.7803342739309747\n"
     ]
    }
   ],
   "source": [
    "show_performance(train_forest('cool', 'oldies'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Trimming input...\n",
      "Training LSTM...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 150, 64)           320064    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 150, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 355,467\n",
      "Trainable params: 355,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 18427 samples, validate on 4607 samples\n",
      "Epoch 1/5\n",
      "18427/18427 [==============================] - 25s 1ms/step - loss: 0.6615 - acc: 0.5960 - val_loss: 0.5832 - val_acc: 0.7076\n",
      "Epoch 2/5\n",
      "18427/18427 [==============================] - 23s 1ms/step - loss: 0.5534 - acc: 0.7349 - val_loss: 0.5480 - val_acc: 0.7374\n",
      "Epoch 3/5\n",
      "18427/18427 [==============================] - 24s 1ms/step - loss: 0.5073 - acc: 0.7686 - val_loss: 0.5272 - val_acc: 0.7543\n",
      "Epoch 4/5\n",
      "18427/18427 [==============================] - 24s 1ms/step - loss: 0.4727 - acc: 0.7963 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 5/5\n",
      "18427/18427 [==============================] - 24s 1ms/step - loss: 0.4386 - acc: 0.8124 - val_loss: 0.5279 - val_acc: 0.7599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x1a3a6c96a0>,\n",
       " array([[ 228,  312,   73, ...,  577,   66,  399],\n",
       "        [  76,  976,  523, ...,  545,   37,  588],\n",
       "        [ 427,  373,    7, ...,  525,    4,    7],\n",
       "        ...,\n",
       "        [1234,   89,    2, ...,    1,   54,  487],\n",
       "        [   8,  615,    8, ...,    8,  615,    8],\n",
       "        [ 326,    2,   85, ...,  686,    4,  125]], dtype=int32),\n",
       " array([0, 0, 1, ..., 0, 1, 1]),\n",
       " array([[  48, 1120,  211, ...,   94,    4,   66],\n",
       "        [  46,   46,   46, ...,  989,   80,  434],\n",
       "        [  88,   72,   22, ...,  105,    0,    0],\n",
       "        ...,\n",
       "        [1110,  390,    7, ...,  616,  180,    3],\n",
       "        [   7,  156,    7, ...,  335,    4,   44],\n",
       "        [   0,    0,    0, ...,   76,    2,  358]], dtype=int32),\n",
       " array([1, 0, 1, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm('cool', 'oldies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Training random forest...\n",
      "Finished.\n",
      "Training accuracy: 0.9870833333333333\n",
      "Validation accuracy: 0.7679067184897279\n"
     ]
    }
   ],
   "source": [
    "show_performance(train_forest('sweet', 'dark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training set...\n",
      "Preprocessing validation set...\n",
      "Trimming input...\n",
      "Training LSTM...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 150, 64)           320064    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 150, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 355,467\n",
      "Trainable params: 355,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7200 samples, validate on 1801 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.6590 - acc: 0.5960 - val_loss: 0.6033 - val_acc: 0.6780\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5216 - acc: 0.7535 - val_loss: 0.5627 - val_acc: 0.7290\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.4570 - acc: 0.8057 - val_loss: 0.5637 - val_acc: 0.7435\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.4110 - acc: 0.8319 - val_loss: 0.5752 - val_acc: 0.7235\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 10s 1ms/step - loss: 0.3750 - acc: 0.8465 - val_loss: 0.6041 - val_acc: 0.7324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x1a33858b70>,\n",
       " array([[ 154,   57,    6, ...,    6,  257,   37],\n",
       "        [  67,    2, 3514, ...,   59,   14, 1255],\n",
       "        [  17,    2,  563, ...,   50,  283,   50],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,    6,  279,    0],\n",
       "        [  25, 3795,   49, ...,   41,   11,   73],\n",
       "        [ 798,  106,    6, ...,   66,  747,  798]], dtype=int32),\n",
       " array([0, 1, 0, ..., 0, 1, 0]),\n",
       " array([[  61,   11, 3252, ...,  200,   92, 2211],\n",
       "        [   3,  110,  392, ...,  392,  110,  392],\n",
       "        [  74,  762,    1, ...,    4,  131,    1],\n",
       "        ...,\n",
       "        [   1,   57, 2539, ...,    0,    0,    0],\n",
       "        [ 290,    6,  138, ...,   92,    1, 3856],\n",
       "        [ 476,   22,  257, ..., 1110,   22,  251]], dtype=int32),\n",
       " array([0, 0, 1, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm('sweet', 'dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the models is summarized as below\n",
    "\n",
    "|                 | happy-sad | relax-energetic | cool-oldies | sweet-dark |\n",
    "|-----------------|-----|---------------|----------------------|---------------------|\n",
    "| baseline model    | 78% | 79%           | 78%                  | 77%                 |\n",
    "| word2vec + LSTM | 74% | 75%           | 76%                  | 73%                 |\n",
    "\n",
    "Althought the performace of the two models are comparable in all four pair of emotions, we found that our baseline model outperformed this new model in all cases. It is possible that with better tuning the accuracy of wrod2vec + LSTM can can be higher, but considering our limited time, we chose our baseline model as our final model for lyrics-based emotion recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3). Final Model for Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built four pipelines for four dimensions of emotion: happy-sad, relax-energetic, cool-oldies, sweet-dark. This time, the model is trained on all our available data for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(X, y):\n",
    "    vectorizer = HashingVectorizer(n_features=1000)\n",
    "  \n",
    "    print('Preprocessing training set...')\n",
    "    X_train_forest = vectorizer.fit_transform(X)\n",
    "    y_train_forest = y\n",
    "    print('Training random forest...')\n",
    "    forest = RandomForestClassifier(\n",
    "        n_estimators=300, max_features=30, max_depth=None, min_samples_split=2)\n",
    "    forest.fit(X_train_forest, y_train_forest)\n",
    "    print('Finished.')\n",
    "    return forest, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_forest_pipeline(res, tag1, tag2):\n",
    "    pipeline = Pipeline([('vectorizer', res[1]), ('forest', res[0])])\n",
    "    dump(pipeline, tag1+'-'+tag2+'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_forest_pipeline(tag1, tag2):\n",
    "    return load(tag1+'-'+tag2+'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(tag1, tag2):\n",
    "    X, y = create_train(tag1, tag2)\n",
    "    res = train_forest(X, y)\n",
    "    save_forest_pipeline(res, tag1, tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "8508 tracks collected for tag happy, 9078 tracks collected for tag sad\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "7721 nonempty lyrics for tag happy, 8302 nonempty lyrics for tag sad\n",
      "Creating predictor set and target set...\n",
      "Preprocessing training set...\n",
      "Training random forest...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_pipeline('happy', 'sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "6287 tracks collected for tag relax, 4521 tracks collected for tag Energetic\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "5214 nonempty lyrics for tag relax, 4072 nonempty lyrics for tag Energetic\n",
      "Creating predictor set and target set...\n",
      "Preprocessing training set...\n",
      "Training random forest...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_pipeline('relax', 'Energetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "12457 tracks collected for tag cool, 12769 tracks collected for tag oldies\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "11062 nonempty lyrics for tag cool, 11969 nonempty lyrics for tag oldies\n",
      "Creating predictor set and target set...\n",
      "Preprocessing training set...\n",
      "Training random forest...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_pipeline('cool', 'oldies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tids...\n",
      "Collecting artists and titles...\n",
      "Collecting lyrics...\n",
      "5169 tracks collected for tag sweet, 4768 tracks collected for tag dark\n",
      "Filtering out empty lyrics...\n",
      "Filtering out non-English lyrics...\n",
      "4774 nonempty lyrics for tag sweet, 4225 nonempty lyrics for tag dark\n",
      "Creating predictor set and target set...\n",
      "Preprocessing training set...\n",
      "Training random forest...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "create_pipeline('sweet', 'dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4). Profiling the Emotion of Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We profiled the tracks in the Million Playlist Dataset using the four piplines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKURI_PATH = 'databases/track_uri.db'\n",
    "PROFILES_PATH = 'databases/profiles.db'\n",
    "\n",
    "conn_trackuri = sqlite3.connect(TRACKURI_PATH)\n",
    "conn_profiles = sqlite3.connect(PROFILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_profiles.execute(\"\"\"CREATE TABLE profiles (\n",
    "                         track_uri TEXT,\n",
    "                         happy_sad REAL,\n",
    "                         relax_energetic REAL,\n",
    "                         cool_oldies REAL,\n",
    "                         sweet_dark REAL)\"\"\")\n",
    "conn_profiles.execute(\"\"\"CREATE INDEX profile_track_uris ON profiles (track_uri)\"\"\")\n",
    "conn_profiles.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Profile the emotion of a song:\n",
    "[\n",
    "1: happy, -1:sad;\n",
    "1: relax, -1:energetic;\n",
    "1: cool,  -1:oldies;\n",
    "1: sweet, -1:dark;\n",
    "]\n",
    "\"\"\"\n",
    "def make_profile(lyrics, pipelinelist):\n",
    "    profiles = np.zeros(shape=(len(lyrics), len(pipelinelist)))\n",
    "    for i, pipeline in enumerate(pipelinelist):\n",
    "        profiles[:, i] = (pipeline.predict_proba(lyrics)[:, 1] - 0.5) * 2.0\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_profiles(urilist, conn_trackuri, conn_wiki, \n",
    "                   conn_profiles):\n",
    "    AandTs = get_artistsandtitles_byuri(urilist, conn_trackuri)\n",
    "    lyrics = get_lyrics(AandTs, conn_wiki)\n",
    "    urilist_, lyrics_ = get_nonempty(urilist, lyrics)\n",
    "    urilist_, lyrics_ = get_english(urilist_, lyrics_)\n",
    "    assert len(urilist_) == len(set(urilist_))\n",
    "    profiles = make_profile(lyrics_, \n",
    "                            [pipeline1, pipeline2, pipeline3, pipeline4])\n",
    "    insertvals = [(uri, profile[0], profile[1], profile[2], profile[3]) \n",
    "                  for uri, profile in zip(urilist_, profiles)]\n",
    "    conn_profiles.executemany(\"\"\"INSERT INTO profiles (track_uri, happy_sad, relax_energetic, cool_oldies, sweet_dark)\n",
    "                             VALUES (?, ?, ?, ?, ?)\"\"\", insertvals)\n",
    "    conn_profiles.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "batch_numb = len(all_uris) // batch_size\n",
    "for i in range(batch_numb+1):\n",
    "    batch = all_uris[batch_size*i: batch_size*(i+1)]\n",
    "    build_profiles(batch, conn_trackuri, conn_wiki, conn_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Audio Feature - Genre Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_of_interest = ['rock','pop','alternative','indie','electronic',\n",
    "                    'jazz','metal','soul','folk','instrumental',\n",
    "                     'punk','blues','Hip-Hop']\n",
    "feature_of_interest = ['danceability','energy','key','loudness','mode','tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## connect to sql database\n",
    "TAG_PATH  = 'lastfm_tags.db'\n",
    "conn_tag  = sqlite3.connect(TAG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data query\n",
    "sql  = \"\"\"SELECT tids.tid, tags.tag, tid_tag.val FROM tid_tag, tids, tags \n",
    "          WHERE tids.ROWID=tid_tag.tid AND tid_tag.tag=tags.ROWID \n",
    "          AND tags.tag in ('rock','pop','alternative','indie','electronic',\n",
    "          'jazz','metal','soul','folk','instrumental','punk','blues','Hip-Hop')\n",
    "          ORDER BY tids.tid\"\"\"\n",
    "tag_data = np.array(conn_tag.execute(sql).fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct empty dictionary\n",
    "data_dict = {track_id:{} for track_id in tag_data[:,0]}\n",
    "for track_id, item in itertools.product(tag_data[:,0], feature_of_interest+genre_of_interest):\n",
    "    data_dict[track_id][item] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill dictionary with tag values\n",
    "for entry in tag_data:\n",
    "    data_dict[entry[0]][entry[1]]=float(entry[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get file paths for songs of interest\n",
    "song_data_path = os.path.join(os.getcwd(),'millionsong','data')\n",
    "sub = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N',\n",
    "        'O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "song_fn = {}\n",
    "for sub1, sub2, sub3 in itertools.product(sub,sub,sub):\n",
    "    song_path = os.path.join(song_data_path,sub1,sub2,sub3)\n",
    "    try:\n",
    "        for fn in os.listdir(song_path):\n",
    "            if fn.split('.')[0] in data_dict:\n",
    "                song_fn[fn.split('.')[0]] = os.path.join(song_path, fn)\n",
    "    except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read audio feature data into the dictionary\n",
    "for fn in song_fn:\n",
    "    s = h5py.File(song_fn[fn], 'r')\n",
    "    analysis = np.array(s.get('analysis').get('songs'))[0]\n",
    "    for feature in feature_of_interest:\n",
    "        data_dict[fn][feature] = analysis[feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn dictionary into dataframe and drop unfound rows\n",
    "data_df = pd.DataFrame.from_dict(data_dict,orient='index')\n",
    "set1 = set(data_dict.keys())\n",
    "set2 = set(song_fn.keys())\n",
    "drop_index = list(set1 - set2)\n",
    "data_df = data_df.drop(drop_index, axis=0)\n",
    "data_df = data_df.drop(['danceability','energy'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data to csv\n",
    "data_df.to_csv('audio_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('audio_tag.csv',index_col = 0)\n",
    "key_dummies = pd.get_dummies(data_df['key'])\n",
    "for key in key_dummies:\n",
    "    data_df.insert(key,'key_'+str(key),key_dummies[[key]])\n",
    "data_df = data_df.drop(columns=['key','key_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_df, test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:,0:14]\n",
    "X_test = test_data.iloc[:,0:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Baseline Model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_logit_scores = {}\n",
    "genre_logit_models = {}\n",
    "\n",
    "for genre in genre_of_interest:\n",
    "    y_train = train_data[genre].values\n",
    "    y_test = test_data[genre].values\n",
    "    tag_train = np.where(y_train > 0,1,0)\n",
    "    tag_test = np.where(y_test > 0,1,0)\n",
    "    Logit = LogisticRegression(solver='liblinear')\n",
    "    Logit.fit(X_train,tag_train)\n",
    "    score = Logit.score(X_test,tag_test)\n",
    "    genre_logit_models[genre] = Logit\n",
    "    genre_logit_scores[genre] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rock': 0.6387224779920251,\n",
       " 'pop': 0.7582108527729086,\n",
       " 'alternative': 0.8030743744341494,\n",
       " 'indie': 0.8300425712249341,\n",
       " 'electronic': 0.8361682044959836,\n",
       " 'jazz': 0.8940149866122166,\n",
       " 'metal': 0.9025677575944369,\n",
       " 'soul': 0.9163600639531524,\n",
       " 'folk': 0.915608807042552,\n",
       " 'instrumental': 0.9237763180706181,\n",
       " 'punk': 0.9243542080018492,\n",
       " 'blues': 0.9262227187794965,\n",
       " 'Hip-Hop': 0.9427503708127059}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_logit_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies are quite high for most of the genres. However, after investigation, we found that it is only because the model is very unbalanced. Comparing the number of all songs, each genre includes very few songs. For example, the classification model for folk songs classifies all songs to be not folk songs, and the accuracy is still higher than 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Improved Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try to balance the model. For each genre classification model, we keep all observations that classify the song as of that genre, and sample twice as many observations that classify the song as not belonging to that genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_logit_scores2 = {}\n",
    "genre_logit_models2 = {}\n",
    "\n",
    "for genre in genre_of_interest:\n",
    "    train_pos = train_data.loc[train_data[genre]>0]\n",
    "    train_neg = train_data.loc[train_data[genre]==0]\n",
    "    train_neg_selected = train_neg.sample(n=min(len(train_neg),2*len(train_pos)),replace=False,random_state=42)\n",
    "    train_full = pd.concat([train_pos,train_neg_selected])\n",
    "\n",
    "    x_train = train_full.iloc[:,0:14]\n",
    "    y_train = train_full[genre].values\n",
    "    y_test = test_data[genre].values\n",
    "    tag_train = np.where(y_train > 0,1,0)\n",
    "    tag_test = np.where(y_test > 0,1,0)\n",
    "    Logit = LogisticRegression(solver='liblinear')\n",
    "    Logit.fit(x_train,tag_train)\n",
    "    score = Logit.score(X_test,tag_test)\n",
    "    genre_logit_models2[genre] = Logit\n",
    "    genre_logit_scores2[genre] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rock': 0.6387224779920251,\n",
       " 'pop': 0.7581338007820777,\n",
       " 'alternative': 0.8027854294685339,\n",
       " 'indie': 0.8299269932386878,\n",
       " 'electronic': 0.8243021979080385,\n",
       " 'jazz': 0.8429680426868029,\n",
       " 'metal': 0.8319881339934121,\n",
       " 'soul': 0.9115635775239342,\n",
       " 'folk': 0.8547955232793327,\n",
       " 'instrumental': 0.8680099397068172,\n",
       " 'punk': 0.8531196424787626,\n",
       " 'blues': 0.865948798952093,\n",
       " 'Hip-Hop': 0.8713039123148344}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_logit_scores2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model is no longer classifying most of the songs as not belonging to any genre. However, the accuracy is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4). Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we try to classify song genre through a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select hyperparameter n_estimators\n",
    "mean_scores = []\n",
    "ns = np.arange(10,51,5)\n",
    "\n",
    "for n in ns:\n",
    "    scores = []\n",
    "    for genre in genre_of_interest:\n",
    "        y_train = train_data[genre].values\n",
    "        y_test = test_data[genre].values\n",
    "        tag_train = np.where(y_train > 0,1,0)\n",
    "        tag_test = np.where(y_test > 0,1,0)\n",
    "        randomforest = RandomForestClassifier(n_estimators=n, max_depth=None)\n",
    "        randomforest.fit(X_train,tag_train)\n",
    "        scores.append(randomforest.score(X_test,tag_test))\n",
    "    mean_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ns,mean_scores)\n",
    "plt.axhline(mean_scores[-3])\n",
    "plt.title('Selection of Number of Trees in Random Forest')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('mean classification accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of trees is 40, the mean classification accuracy is the highest, and it requires less computation power than having 50 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_rf_scores = {}\n",
    "genre_rf_models = {}\n",
    "\n",
    "for genre in genre_of_interest:\n",
    "    y_train = train_data[genre].values\n",
    "    y_test = test_data[genre].values\n",
    "    tag_train = np.where(y_train > 0,1,0)\n",
    "    tag_test = np.where(y_test > 0,1,0)\n",
    "    \n",
    "    randomforest = RandomForestClassifier(n_estimators=40, max_depth=None)\n",
    "    randomforest.fit(X_train,tag_train)\n",
    "    score = randomforest.score(X_test,tag_test)\n",
    "    genre_rf_models[genre] = randomforest\n",
    "    genre_rf_scores[genre] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rock': 0.6075549477009612,\n",
       " 'pop': 0.7153892088686842,\n",
       " 'alternative': 0.7731396759963786,\n",
       " 'indie': 0.8058482461040587,\n",
       " 'electronic': 0.8222603201510219,\n",
       " 'jazz': 0.884961377689596,\n",
       " 'metal': 0.8916841638895845,\n",
       " 'soul': 0.908924546837979,\n",
       " 'folk': 0.9087319168609019,\n",
       " 'instrumental': 0.9185560456918306,\n",
       " 'punk': 0.9168223758981373,\n",
       " 'blues': 0.9197696145474159,\n",
       " 'Hip-Hop': 0.9382813553445187}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_rf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model is less affected by the unbalanced problem, and it produces higher accuracies than the balanced Logistic Regression models. Thus, we choose to use Random Forest to classify genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5). Profiling the Genres of Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPD_audio = pd.read_csv('MPD_audio.csv')\n",
    "\n",
    "key_dummies_MPD = pd.get_dummies(MPD_audio['key'])\n",
    "for key in key_dummies_MPD:\n",
    "    MPD_audio.insert(key+1,'key_'+str(key),key_dummies_MPD[[key]])\n",
    "MPD_audio = MPD_audio.drop(columns=['key','key_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genre_of_interest:\n",
    "    proba = genre_rf_models[genre].predict_proba(MPD_audio.iloc[:,1:15])\n",
    "    MPD_audio[genre] = proba[:,1]\n",
    "\n",
    "MPD_audio.to_csv('MPD_genre_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENREPROFILES_PATH = 'databases/genre_profiles.db'\n",
    "conn_genreprofiles = sqlite3.connect(GENREPROFILES_PATH)\n",
    "\n",
    "genre_df = pd.read_csv('MPD_genre.csv')\n",
    "genre_df.to_sql('profiles', con=conn_genreprofiles, index=False)\n",
    "conn_genreprofiles.execute(\"\"\"CREATE INDEX profile_track_uris ON profiles (track_uri)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Full Audio Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used only part of the audio features data from the Spotify API to classify the genres of the songs. The full audio feature data are too inserted into a relational database for latter use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1). Profiling the Audio Features of Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIOPROFILES_PATH = 'databases/audio_profiles.db'\n",
    "conn_audioprofiles = sqlite3.connect(AUDIOPROFILES_PATH)\n",
    "\n",
    "audio_df = pd.read_csv('MPD_audio_full.csv')\n",
    "audio_df.to_sql('profiles', con=conn_audioprofiles, index=False)\n",
    "# build index to accelerate querying\n",
    "conn_audioprofiles.execute(\"\"\"CREATE INDEX profile_track_uris ON profiles (track_uri)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Recommendation Based on Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations were generated by finding tracks that has most similar profiles as the input (seeding) tracks. The similarity is defined by cosine similarity and the we achived efficient retrieval of similarity neighbors by putting all our tracks into a KD-tree (It can be proved that when the profiles are normalized, the tracks that have smallest euclidean distances are the tracks that have the highest cosine similarity). To address the problem that the tracks in an input playlist may not be homogeneous, we first perform a clustering on the input tracks and then give recommendations based on each clustering center. For each generated playlist is generated, we linearly score the tracks, i.e. the i-th closest track to the seed has a score of 1 - i/(# tracks generated per playlist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"functions to query database for titles and profiles\"\"\"\n",
    "def get_titles(seed_urilist):\n",
    "    titles   = [get_title_byuri(uri) for uri in seed_urilist]\n",
    "    return [t for t in titles if t is not None]\n",
    "def get_profiles(seed_urilist, conn_profiles):\n",
    "    profiles = [get_profile_byuri(uri, conn_profiles) for uri in seed_urilist]\n",
    "    return np.array([p for p in profiles if p is not None])\n",
    "def get_title_byuri(uri):\n",
    "    sql  = \"SELECT track_name FROM track_uri WHERE track_uri='{}'\".format(uri)\n",
    "    res  = conn_trackuri.execute(sql)\n",
    "    try:\n",
    "        return res.fetchall()[0][0]\n",
    "    except:\n",
    "        return None\n",
    "def get_profile_byuri(uri, conn_profiles):\n",
    "    sql  = \"SELECT * FROM profiles WHERE track_uri='{}'\".format(uri)\n",
    "    res  = conn_profiles.execute(sql)\n",
    "    try:\n",
    "        return res.fetchall()[0][1:]\n",
    "    except:\n",
    "        return None\n",
    "def get_all_profiles(conn_profiles, dropnull=False):\n",
    "    sql  = \"\"\"SELECT * from profiles\"\"\"\n",
    "    res  = conn_profiles.execute(sql)\n",
    "    data = res.fetchall()\n",
    "    if dropnull:\n",
    "        for p in data:\n",
    "            if None in p: data.remove(p)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"set up kdtree for a certain kind of profiles\"\"\"\n",
    "def build_kdtree(conn_profiles):\n",
    "    print('Reading profiles from sqlite...')\n",
    "    all_profiles = get_all_profiles(conn_profiles, dropnull=True)\n",
    "    print('Creating dictionary got URI ...')\n",
    "    dict_ind2uri = {i: t[0] for i, t in enumerate(all_profiles)}\n",
    "    dict_uri2ind = {v: k    for k, v in dict_ind2uri.items()   }\n",
    "    print('Building KD-tree...')\n",
    "    profile_values = np.array([t[1:] for t in all_profiles])\n",
    "    # profiles are normalized so that their euclidian neighbors are also their cosine-similarity neighbors\n",
    "    profile_values = normalize(profile_values) \n",
    "    kdtree = KDTree(profile_values, leaf_size=2)\n",
    "    return kdtree, dict_ind2uri, dict_uri2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"make recommendation based on single seed profile\"\"\"\n",
    "def get_recm_byprofile(seed_profile, kdtree, dict_ind2uri, exclude_titles, num_recm):\n",
    "    search_ratio = 2\n",
    "    while True:\n",
    "        _,    ind = kdtree.query([seed_profile], k=num_recm*search_ratio)\n",
    "        recm_list = []\n",
    "        for recm_ind in ind[0]:\n",
    "            recm_uri   = dict_ind2uri[recm_ind]\n",
    "            recm_title = get_title_byuri(recm_uri)\n",
    "            if recm_title in exclude_titles: continue\n",
    "            recm_list.append(recm_uri)\n",
    "            if len(recm_list) == num_recm:   return recm_list\n",
    "        if len(recm_list) < num_recm: search_ratio *= 2\n",
    "    return recm_list\n",
    "\"\"\"make recommendation based on multiple seed profiles\"\"\"\n",
    "def create_recommendations(seed_profiles, kdtree, dict_ind2uri, exclude_titles, num_recm=500, num_cntr=None):\n",
    "    if len(seed_profiles) == 0: return []\n",
    "    num_seed = len(seed_profiles)\n",
    "    if num_cntr is None: num_cntr = int(np.sqrt(num_seed))\n",
    "    kmeans = KMeans(n_clusters=num_cntr).fit(seed_profiles)\n",
    "    num_recm_per_cntr = int(num_recm/num_cntr)+1\n",
    "    lists = []\n",
    "    for c in kmeans.cluster_centers_:\n",
    "        lists.append( get_recm_byprofile(c, kdtree, dict_ind2uri, exclude_titles, num_recm_per_cntr) )\n",
    "    recm_list = [None] * num_cntr * num_recm_per_cntr\n",
    "    for i in range(num_cntr):\n",
    "        recm_list[i::num_cntr] = lists[i]\n",
    "    return recm_list[:num_recm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_val_Y(val_X, conn_profiles, kdtree, dict_ind2uri, num_recm_per_list, verbose=True):\n",
    "    val_Y = []\n",
    "    total = len(val_X); every = total // 100\n",
    "    for i, seedlist in enumerate(val_X):\n",
    "        titles   = get_titles(seedlist)\n",
    "        profiles = get_profiles(seedlist, conn_profiles)\n",
    "        val_Y.append( create_recommendations(profiles, kdtree, dict_ind2uri, \n",
    "                                             exclude_titles=titles, num_recm=num_recm_per_list) )\n",
    "        if verbose and i%every == 0: print('{0:3d} / 100 finished'.format(i//every))\n",
    "    return val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading profiles from sqlite...\n",
      "Creating dictionary got URI ...\n",
      "Building KD-tree...\n"
     ]
    }
   ],
   "source": [
    "genrekdtree, genredict_ind2uri, genredict_uri2ind = build_kdtree(conn_genreprofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreval_Y = generate_val_Y(val_X, conn_genreprofiles, genrekdtree, genredict_ind2uri, 500, verbose=True)\n",
    "with open('val_Y_genre.json', 'w') as f:\n",
    "    json.dump(genreval_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading profiles from sqlite...\n",
      "Creating dictionary got URI ...\n",
      "Building KD-tree...\n"
     ]
    }
   ],
   "source": [
    "audiokdtree, audiodict_ind2uri, audiodict_uri2ind = build_kdtree(conn_audioprofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioval_Y = generate_val_Y(val_X, conn_audioprofiles, audiokdtree, audiodict_ind2uri, 500, verbose=True)\n",
    "with open('val_Y_audio.json', 'w') as f:\n",
    "    json.dump(audioval_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading profiles from sqlite...\n",
      "Creating dictionary got URI ...\n",
      "Building KD-tree...\n"
     ]
    }
   ],
   "source": [
    "lyrickdtree, lyricdict_ind2uri, lyricdict_uri2ind = build_kdtree(conn_lyricprofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricval_Y = generate_val_Y(val_X, conn_lyricprofiles, lyrickdtree, lyricdict_ind2uri, 500, verbose=True)\n",
    "with open('val_Y_lyric.json', 'w') as f:\n",
    "    json.dump(lyricval_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(val_Y, method='linear'):\n",
    "    scores = []\n",
    "    length = len(val_Y[0])\n",
    "    if method == 'linear':\n",
    "        for l in val_Y:\n",
    "            score_dict = {}\n",
    "            for i, t in enumerate(l):\n",
    "                score_dict[t] = 1-i/length\n",
    "            scores.append(score_dict)\n",
    "    elif method == 'exp':\n",
    "        for l in val_Y:\n",
    "            score_dict = {}\n",
    "            for i, t in enumerate(l):\n",
    "                score_dict[t] = np.exp(-4*i/length)\n",
    "            scores.append(score_dict)\n",
    "    else: raise ValueError('method not found')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreval_Y_score = scoring(genreval_Y)\n",
    "audioval_Y_score = scoring(audioval_Y)\n",
    "lyricval_Y_score = scoring(lyricval_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
